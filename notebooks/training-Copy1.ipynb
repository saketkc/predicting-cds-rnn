{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-05T00:14:23.876173Z",
     "start_time": "2017-11-05T00:14:23.824776Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import importlib\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM\n",
    "#Dropout, RepeatVector, TimeDistributed, AveragePooling1D, Flatten\n",
    "from collections import defaultdict, OrderedDict\n",
    "from scipy.stats import describe\n",
    "\n",
    "def set_keras_backend(backend):\n",
    "    if K.backend() != backend:\n",
    "        os.environ['KERAS_BACKEND'] = backend\n",
    "        importlib.reload(K)\n",
    "        assert K.backend() == backend\n",
    "\n",
    "\n",
    "#set_keras_backend('theano')\n",
    "__BASES__ = ['A','C','G','T']\n",
    "__BASES_MAP__ = OrderedDict(zip(__BASES__,range(4)))\n",
    "__MERGE_KEYS__ = ['UTR5', 'CDS', 'UTR3']\n",
    "__MERGE_LABELS__ = OrderedDict(zip(__MERGE_KEYS__,range(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-05T00:07:29.969321Z",
     "start_time": "2017-11-05T00:07:29.794309Z"
    }
   },
   "outputs": [],
   "source": [
    "def _downsample(genes_histogram, genes_to_keep=5000):\n",
    "    \"\"\"Downsample a histogram by randomly dropping proportional\n",
    "    number of genes in each bin\n",
    "\n",
    "    Params\n",
    "    ------\n",
    "\n",
    "    genes_histogram : dict\n",
    "        Dictionary with format {bin:[list of genes in bin]}\n",
    "\n",
    "    genes_to_keep : int\n",
    "        Total genes to keep\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    downsampled_dict : dict\n",
    "        Dictionary with downsampled list in each bin\n",
    "\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    downsampled_dict = {}\n",
    "    total_bins = len(genes_histogram)\n",
    "    total_genes = sum([len(x) for x in list(genes_histogram.values())])\n",
    "    scaling_factor = genes_to_keep / total_genes\n",
    "    for bin_index, genes_in_bin in list(genes_histogram.items()):\n",
    "        n_genes_in_bin = len(genes_in_bin)\n",
    "        n_genes_to_keep = int(np.ceil(n_genes_in_bin * scaling_factor))\n",
    "        index_genes_to_keep = np.random.choice(n_genes_in_bin, n_genes_to_keep)\n",
    "        genes_to_keep = np.array(genes_in_bin)[index_genes_to_keep]\n",
    "        downsampled_dict[bin_index] = list(genes_to_keep)\n",
    "    return downsampled_dict\n",
    "\n",
    "\n",
    "def load_data(gene_cds, gene_lengths, genes_to_keep=5000):\n",
    "    \"\"\"Load dataset\n",
    "\n",
    "    Params\n",
    "    ------\n",
    "    gene_cds : str\n",
    "        Path to json with sequence\n",
    "\n",
    "    gene_lengths : str\n",
    "        Path to json with sequence lengths\n",
    "\n",
    "    genes_to_keep : int\n",
    "        Total genes_to_keep\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    downsampled_genes_dict : dict\n",
    "        Dictionary with format {bin:[list of genes in bin]}\n",
    "\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "\n",
    "    gene_seq = OrderedDict(json.load(open(gene_cds)))\n",
    "    gene_len = OrderedDict(json.load(open(gene_lengths)))\n",
    "\n",
    "    gene_total_len = OrderedDict((k, sum(list(v.values())))\n",
    "                                 for k, v in list(gene_len.items()))\n",
    "    all_lengths = np.array(list(gene_total_len.values()))\n",
    "    valid_genes_dict = OrderedDict((k, v)\n",
    "                                   for k, v in list(gene_total_len.items())\n",
    "                                   if v < 10000)\n",
    "\n",
    "    valid_genes_keys = list(valid_genes_dict.keys())\n",
    "    valid_genes_values = list(valid_genes_dict.values())\n",
    "    hist, edges = np.histogram(valid_genes_values)\n",
    "    valid_genes_bins = np.digitize(valid_genes_values, edges)\n",
    "    length_wise_binned_genes = defaultdict(list)\n",
    "    for i, b in enumerate(valid_genes_bins):\n",
    "        length_wise_binned_genes[b - 1].append(valid_genes_keys[i])\n",
    "\n",
    "    downsampled_genes_dict = _downsample(length_wise_binned_genes, \n",
    "                                         genes_to_keep=5000)\n",
    "    return downsampled_genes_dict, gene_seq\n",
    "\n",
    "\n",
    "def split_train_test_genes(length_wise_binned_genes, train_proportion=0.7):\n",
    "    \"\"\"Split data in training and testing set\n",
    "\n",
    "    Params\n",
    "    ------\n",
    "    length_wise_binned_genes : dict\n",
    "         Dictionary with format {bin:[list of genes in bin]}\n",
    "\n",
    "    train_proportion : float\n",
    "        Training proportion\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    training_genes : list\n",
    "\n",
    "    testing_genes : list\n",
    "\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    training_genes = []\n",
    "    testing_genes = []\n",
    "    for bin_number, bin_genes in list(length_wise_binned_genes.items()):\n",
    "        n_genes = len(bin_genes)\n",
    "        np.random.shuffle(bin_genes)\n",
    "        training_genes += bin_genes[:int(n_genes * train_proportion)]\n",
    "        testing_genes += bin_genes[int(n_genes * train_proportion):]\n",
    "\n",
    "    return training_genes, testing_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-05T00:04:14.864552Z",
     "start_time": "2017-11-05T00:04:14.845420Z"
    }
   },
   "outputs": [],
   "source": [
    "def map_base_to_int(base):\n",
    "    \"\"\"Return int given a base character\"\"\"\n",
    "    return __BASES_MAP__[base]\n",
    "\n",
    "\n",
    "def one_hot_encoding(data_dict):\n",
    "    \"\"\"One hot encode sequences\n",
    "\n",
    "    Params\n",
    "    ------\n",
    "    data_dict : dict\n",
    "        Sequence dict as loaded from gene_cds json file\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    X : array\n",
    "        X*4 Input array with columns representing A,T,G,C\n",
    "\n",
    "    Y : array\n",
    "        X*3 Labels with columns representing 5'UTR, CDS, 3'UTR\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    merged_seq = []\n",
    "    merged_label = []\n",
    "    for key in __MERGE_KEYS__:\n",
    "        merged_seq += list(data_dict[key])\n",
    "        merged_label += list([__MERGE_LABELS__[key]] * len(data_dict[key]))\n",
    "    merged_seq_int = list(map(map_base_to_int, merged_seq))\n",
    "\n",
    "    X = to_categorical(merged_seq_int)\n",
    "    Y = to_categorical(merged_label)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-05T01:21:52.106178Z",
     "start_time": "2017-11-05T01:21:52.022835Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(X_train, Y_train, X_test, Y_test):\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        LSTM(\n",
    "            3,\n",
    "            return_sequences=True,\n",
    "            input_shape=(None, 4),\n",
    "            dropout=0.25,\n",
    "            recurrent_dropout=0.25))\n",
    "    model.add(Dense(3, activation='sigmoid'))\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='rmsprop',\n",
    "        metrics=['accuracy'])\n",
    "    nb_epoch = 128\n",
    "    train_history = defaultdict(list)\n",
    "    test_history = defaultdict(list)\n",
    "    \n",
    "    for e in range(nb_epoch):\n",
    "        index = 0\n",
    "        for x, y in zip(X_train, Y_train):\n",
    "            acc = model.train_on_batch(np.array([x]), np.array([y]))\n",
    "            train_history[e].append(acc)\n",
    "            if (index%500) == 0:\n",
    "                sys.stderr.write('Epoch: {} || Index :{} || loss: {} || acc: {}\\n'.format(e, index, acc[0], acc[1]))\n",
    "                ##for x_test, y_test in zip(X_test, Y_test):\n",
    "                ##    prediction = model.evaluate(np.array([x_test]),np.array([y_test]), batch_size=1)\n",
    "                ##    print (prediction)\n",
    "            index += 1\n",
    "        if (e%10==0):\n",
    "            acc_test = 0\n",
    "            for x_test, y_test in zip(X_test, Y_test):\n",
    "                #acc_test = model.predict_classes(np.array([x_test]), batch_size=1)\n",
    "                acc = model.evaluate(np.array([x_test]),np.array([y_test]), batch_size=1)\n",
    "                acc_test += acc[1] \n",
    "            acc_test /= len(X_test)\n",
    "            test_history[e].append(acc_test)\n",
    "            sys.stdout.write('Epoch: {} || Test acc: {}\\n'.format(e, acc_test))\n",
    "            \n",
    "        model.save('lstm-dropout_025_recur_dropout_025-epoch-{}.h5'.format(e))\n",
    "    \n",
    "    return model, train_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-05T00:04:16.256946Z",
     "start_time": "2017-11-05T00:04:16.253069Z"
    }
   },
   "outputs": [],
   "source": [
    "gene_cds = '../data/hg38/input/genes_cds.json'\n",
    "gene_lengths = '../data/hg38/input/genes_lengths.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-05T00:07:45.226877Z",
     "start_time": "2017-11-05T00:07:44.380127Z"
    }
   },
   "outputs": [],
   "source": [
    "genes_dict, gene_seq = load_data(gene_cds, gene_lengths, genes_to_keep=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-05T00:10:01.453402Z",
     "start_time": "2017-11-05T00:09:53.252985Z"
    }
   },
   "outputs": [],
   "source": [
    "training_genes, test_genes = split_train_test_genes(genes_dict, train_proportion=0.7)\n",
    "\n",
    "## Shuffle the genes once again to avoid any bin wise correlation\n",
    "\n",
    "np.random.shuffle(training_genes)\n",
    "np.random.shuffle(test_genes)\n",
    "\n",
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "for gene in training_genes:\n",
    "    X, Y = one_hot_encoding(gene_seq[gene])\n",
    "    X_train.append(X)\n",
    "    Y_train.append(Y)\n",
    "\n",
    "for gene in test_genes:\n",
    "    X, Y = one_hot_encoding(gene_seq[gene])\n",
    "    X_test.append(X)\n",
    "    Y_test.append(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-05T01:21:58.135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 || Index :0 || loss: 1.0946756601333618 || acc: 0.3921380639076233\n",
      "Epoch: 0 || Index :500 || loss: 0.915203332901001 || acc: 0.5043424367904663\n"
     ]
    }
   ],
   "source": [
    "model, trainhist = train(X_train, Y_train, X_test, Y_test)\n",
    "model.save('lstm-dropout_025_recur_dropout_025-all.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_hist_025_recur_dropout_025.pickle', 'wb') as f:\n",
    "    pickle.dump(trainhist, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35_tf]",
   "language": "python",
   "name": "conda-env-py35_tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
